\begin{appendices}
\linespread{1.0}
\renewcommand{\thechapter}{\Alph{chapter}.}
\chapter{Smoothed Particle Hydrodynamics}
\section{Smoothing Kernels}
\begin{python}
def W_poly6_2D(r, h):
    '''
    :param r: A 2d matrix where each column is a vector
    :param h: Support radius
    :return:
    '''
    assert r.shape[0] == 2

    # We determine the length of the vectors and pick out those with length below h
    r_norm = np.linalg.norm(r, axis=0)
    W = np.zeros(r_norm.shape)
    W_i = np.where(r_norm < h)

    # We determine the weights
    c = 4 / (np.pi * np.power(h, 8))
    h2 = np.power(h, 2)
    W[W_i] = c * np.power(h2 - np.power(r_norm[W_i], 2), 3)

    # We normalize the weights so that they add up to 1
    W_sum = np.sum(W)
    W = W / W_sum

    return W

def spiky_2D(r, h):
    assert r.shape[0] == 2

    r_norm = np.linalg.norm(r, axis=0)
    W = np.zeros(r_norm.shape)
    W_i = np.where(r_norm < h)

    c = 15 / (np.pi * np.power(h, 6))
    h2 = np.power(h, 2)
    W[W_i] = c * np.power(h - np.abs(r_norm[W_i]), 3)

    # We normalize the weights so that they add up to 1
    W_sum = np.sum(W)
    W = W / W_sum

    return W
\end{python}

\chapter{Deep Learning}
\section{Loss Function}
\label{lf}
\begin{python}
def loss_func(y_true, y_pred):
    # remove 0 in y_true
    flags = tf.to_float(K.not_equal(y_true, 0.0))
    return K.mean(K.square((y_pred - y_true) * flags), axis=-1)
\end{python}

\section{CNN architecture}
\label{cnnn}
\begin{python}
def build_model(self, input_shape, output_shape):
        self.model.add(
            Conv2D(
                32,
                (3, 3),
                padding='same',
                kernel_regularizer=keras.regularizers.l2(self.weight_decay),
                kernel_initializer='he_normal',
                input_shape=input_shape))
        self.model.add(Activation('relu'))

        self.model.add(
            Conv2D(
                32,
                (3, 3),
                padding='same',
                kernel_regularizer=keras.regularizers.l2(self.weight_decay),
                kernel_initializer='he_normal',
                input_shape=input_shape))
        self.model.add(Activation('relu'))

        self.model.add(MaxPooling2D(pool_size=(2, 2),
                                    strides=(2, 2),
                                    padding='same'))

        self.model.add(
            Conv2D(
                64,
                (3, 3),
                padding='same',
                kernel_regularizer=keras.regularizers.l2(self.weight_decay),
                kernel_initializer='he_normal'))
        self.model.add(Activation('relu'))

        self.model.add(
            Conv2D(
                64,
                (3, 3),
                padding='same',
                kernel_regularizer=keras.regularizers.l2(self.weight_decay),
                kernel_initializer='he_normal'))
        self.model.add(Activation('relu'))

        self.model.add(
            Conv2D(
                64,
                (2, 2),
                padding='same',
                kernel_regularizer=keras.regularizers.l2(self.weight_decay),
                kernel_initializer='he_normal'))
        self.model.add(Activation('relu'))

        self.model.add(MaxPooling2D(pool_size=(2, 2),
                                    strides=(2, 2),
                                    padding='same'))

        self.model.add(BatchNormalization())
        self.model.add(
            Conv2D(
                128,
                (2, 2),
                padding='same',
                kernel_regularizer=keras.regularizers.l2(self.weight_decay),
                kernel_initializer='he_normal'))
        self.model.add(Activation('relu'))

        self.model.add(
            Conv2D(
                128,
                (2, 2),
                padding='same',
                kernel_regularizer=keras.regularizers.l2(self.weight_decay),
                kernel_initializer='he_normal'))
        self.model.add(Activation('relu'))

        self.model.add(
            Conv2D(
                128,
                (2, 2),
                padding='same',
                kernel_regularizer=keras.regularizers.l2(self.weight_decay),
                kernel_initializer='he_normal'))
        self.model.add(Activation('relu'))

        self.model.add(MaxPooling2D(pool_size=(2, 2),
                                    strides=(2, 2),
                                    padding='same'))

        self.model.add(
            Conv2D(
                256,
                (2, 2),
                padding='same',
                kernel_regularizer=keras.regularizers.l2(self.weight_decay),
                kernel_initializer='he_normal'))
        self.model.add(Activation('relu'))

        self.model.add(
            Conv2D(
                256,
                (2, 2),
                padding='same',
                kernel_regularizer=keras.regularizers.l2(self.weight_decay),
                kernel_initializer='he_normal'))
        self.model.add(Activation('relu'))

        self.model.add(
            Conv2D(
                256,
                (2, 2),
                padding='same',
                kernel_regularizer=keras.regularizers.l2(self.weight_decay),
                kernel_initializer='he_normal'))
        self.model.add(Activation('relu'))

        self.model.add(MaxPooling2D(pool_size=(2, 2),
                                    strides=(2, 2),
                                    padding='same'))

        self.model.add(BatchNormalization())
        self.model.add(
            Conv2D(
                512,
                (2, 2),
                padding='same',
                kernel_regularizer=keras.regularizers.l2(self.weight_decay),
                kernel_initializer='he_normal'))
        self.model.add(Activation('relu'))
        self.model.add(
            Conv2D(
                512,
                (2, 2),
                padding='same',
                kernel_regularizer=keras.regularizers.l2(self.weight_decay),
                kernel_initializer='he_normal'))
        self.model.add(Activation('relu'))
        self.model.add(
            Conv2D(
                512,
                (2, 2),
                padding='same',
                kernel_regularizer=keras.regularizers.l2(self.weight_decay),
                kernel_initializer='he_normal'))
        self.model.add(Activation('relu'))

        self.model.add(Dropout(self.dropout))
        self.model.add(Flatten())
        
        output_size = output_shape[0]

        self.model.add(Dense(output_size))
        self.model.add(Activation('relu'))
\end{python}

\section{Learning Rate Scheduler}
\label{lr}
\begin{python}
def scheduler(epoch):
    if epoch <= 100:
        return 0.05
    if epoch <= 400:
        return 0.02
    return 0.01
\end{python}
    
\end{appendices}